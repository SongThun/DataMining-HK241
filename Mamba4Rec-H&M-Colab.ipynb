{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":31254,"databundleVersionId":3103714,"sourceType":"competition"},{"sourceId":9821334,"sourceType":"datasetVersion","datasetId":6001919}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\n\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:55:33.045432Z","iopub.execute_input":"2024-11-11T09:55:33.045721Z","iopub.status.idle":"2024-11-11T09:55:33.056182Z","shell.execute_reply.started":"2024-11-11T09:55:33.045669Z","shell.execute_reply":"2024-11-11T09:55:33.055277Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install recbole mamba-ssm ray kmeans-pytorch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:55:33.057738Z","iopub.execute_input":"2024-11-11T09:55:33.058025Z","iopub.status.idle":"2024-11-11T09:56:11.523480Z","shell.execute_reply.started":"2024-11-11T09:55:33.057995Z","shell.execute_reply":"2024-11-11T09:56:11.522275Z"}},"outputs":[{"name":"stdout","text":"Collecting recbole\n  Downloading recbole-1.2.0-py3-none-any.whl.metadata (1.4 kB)\nCollecting mamba-ssm\n  Downloading mamba_ssm-2.2.2.tar.gz (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: ray in /opt/conda/lib/python3.10/site-packages (2.24.0)\nCollecting kmeans-pytorch\n  Downloading kmeans_pytorch-0.3-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from recbole) (2.4.0)\nRequirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from recbole) (1.26.4)\nRequirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from recbole) (1.14.1)\nRequirement already satisfied: pandas>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from recbole) (2.2.2)\nRequirement already satisfied: tqdm>=4.48.2 in /opt/conda/lib/python3.10/site-packages (from recbole) (4.66.4)\nCollecting colorlog==4.7.2 (from recbole)\n  Downloading colorlog-4.7.2-py2.py3-none-any.whl.metadata (9.9 kB)\nCollecting colorama==0.4.4 (from recbole)\n  Downloading colorama-0.4.4-py2.py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: scikit-learn>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from recbole) (1.2.2)\nRequirement already satisfied: pyyaml>=5.1.0 in /opt/conda/lib/python3.10/site-packages (from recbole) (6.0.2)\nRequirement already satisfied: tensorboard>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from recbole) (2.16.2)\nCollecting thop>=0.1.1.post2207130030 (from recbole)\n  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: tabulate>=0.8.10 in /opt/conda/lib/python3.10/site-packages (from recbole) (0.9.0)\nRequirement already satisfied: plotly>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from recbole) (5.22.0)\nRequirement already satisfied: texttable>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from recbole) (1.7.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from mamba-ssm) (21.3)\nRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from mamba-ssm) (1.11.1.1)\nCollecting einops (from mamba-ssm)\n  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\nCollecting triton (from mamba-ssm)\n  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from mamba-ssm) (4.45.1)\nRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from ray) (8.1.7)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from ray) (3.15.1)\nRequirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from ray) (4.22.0)\nRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ray) (1.0.8)\nRequirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/conda/lib/python3.10/site-packages (from ray) (3.20.3)\nRequirement already satisfied: aiosignal in /opt/conda/lib/python3.10/site-packages (from ray) (1.3.1)\nRequirement already satisfied: frozenlist in /opt/conda/lib/python3.10/site-packages (from ray) (1.4.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from ray) (2.32.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.0->recbole) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.0->recbole) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.0->recbole) (2024.1)\nRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly>=4.0.0->recbole) (8.3.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.23.2->recbole) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.23.2->recbole) (3.5.0)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.5.0->recbole) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.5.0->recbole) (1.62.2)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.5.0->recbole) (3.6)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.5.0->recbole) (70.0.0)\nRequirement already satisfied: six>1.9 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.5.0->recbole) (1.16.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.5.0->recbole) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.5.0->recbole) (3.0.4)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->recbole) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->recbole) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->recbole) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->recbole) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->recbole) (2024.6.1)\nRequirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray) (23.2.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray) (0.35.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray) (0.18.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->mamba-ssm) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->ray) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->ray) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->ray) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->ray) (2024.8.30)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers->mamba-ssm) (0.25.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->mamba-ssm) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers->mamba-ssm) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers->mamba-ssm) (0.20.0)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard>=2.5.0->recbole) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->recbole) (1.3.0)\nDownloading recbole-1.2.0-py3-none-any.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\nDownloading colorlog-4.7.2-py2.py3-none-any.whl (10 kB)\nDownloading kmeans_pytorch-0.3-py3-none-any.whl (4.4 kB)\nDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\nDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: mamba-ssm\n  Building wheel for mamba-ssm (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for mamba-ssm: filename=mamba_ssm-2.2.2-cp310-cp310-linux_x86_64.whl size=323998290 sha256=a658a5438dbe9fb3a53799d7d9f4714ca09225769c24ec04a403728ac7d1c69e\n  Stored in directory: /root/.cache/pip/wheels/57/7c/90/9f963468ecc3791e36e388f9e7b4a4e1e3f90fbb340055aa4d\nSuccessfully built mamba-ssm\nInstalling collected packages: colorlog, triton, kmeans-pytorch, einops, colorama, thop, recbole, mamba-ssm\n  Attempting uninstall: colorlog\n    Found existing installation: colorlog 6.8.2\n    Uninstalling colorlog-6.8.2:\n      Successfully uninstalled colorlog-6.8.2\n  Attempting uninstall: colorama\n    Found existing installation: colorama 0.4.6\n    Uninstalling colorama-0.4.6:\n      Successfully uninstalled colorama-0.4.6\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbayesian-optimization 1.5.1 requires colorama<0.5.0,>=0.4.6, but you have colorama 0.4.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed colorama-0.4.4 colorlog-4.7.2 einops-0.8.0 kmeans-pytorch-0.3 mamba-ssm-2.2.2 recbole-1.2.0 thop-0.1.1.post2209072238 triton-3.1.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport time","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:56:11.525100Z","iopub.execute_input":"2024-11-11T09:56:11.525441Z","iopub.status.idle":"2024-11-11T09:56:14.429549Z","shell.execute_reply.started":"2024-11-11T09:56:11.525404Z","shell.execute_reply":"2024-11-11T09:56:14.428564Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Data preparation","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working\n%cp -r /kaggle/input/h-and-m-run-file ./\n%cd h-and-m-run-file\n%mkdir dataset\n%mkdir dataset/hm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:56:14.431761Z","iopub.execute_input":"2024-11-11T09:56:14.432174Z","iopub.status.idle":"2024-11-11T09:56:17.669661Z","shell.execute_reply.started":"2024-11-11T09:56:14.432141Z","shell.execute_reply":"2024-11-11T09:56:17.667994Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n/kaggle/working/h-and-m-run-file\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"dtype={\"article_id\": str}\ninter = pd.read_csv(\"/kaggle/input/h-and-m-personalized-fashion-recommendations/transactions_train.csv\", dtype=dtype)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:56:17.673165Z","iopub.execute_input":"2024-11-11T09:56:17.674083Z","iopub.status.idle":"2024-11-11T09:57:26.129846Z","shell.execute_reply.started":"2024-11-11T09:56:17.674040Z","shell.execute_reply":"2024-11-11T09:57:26.128763Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"inter[\"timestamp\"] = pd.to_datetime(inter[\"t_dat\"]).astype(int) / 10 ** 9\ndata = inter[inter[\"timestamp\"] > inter[\"timestamp\"].quantile(1-1/64)][[\"customer_id\", \"article_id\", \"timestamp\"]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:57:26.131232Z","iopub.execute_input":"2024-11-11T09:57:26.131570Z","iopub.status.idle":"2024-11-11T09:57:31.922007Z","shell.execute_reply.started":"2024-11-11T09:57:26.131535Z","shell.execute_reply":"2024-11-11T09:57:31.920971Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"user_seqs = data.groupby(\"customer_id\")[\"article_id\"].agg(list).reset_index()[\"customer_id\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:57:31.923205Z","iopub.execute_input":"2024-11-11T09:57:31.923507Z","iopub.status.idle":"2024-11-11T09:57:35.723715Z","shell.execute_reply.started":"2024-11-11T09:57:31.923475Z","shell.execute_reply":"2024-11-11T09:57:35.722917Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_ids, test_ids = train_test_split(user_seqs, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:57:35.724795Z","iopub.execute_input":"2024-11-11T09:57:35.725075Z","iopub.status.idle":"2024-11-11T09:57:37.030668Z","shell.execute_reply.started":"2024-11-11T09:57:35.725044Z","shell.execute_reply":"2024-11-11T09:57:37.029763Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"train_df = data[data[\"customer_id\"].isin(train_ids)]\ntest_df = data[data[\"customer_id\"].isin(test_ids)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:57:37.035575Z","iopub.execute_input":"2024-11-11T09:57:37.036084Z","iopub.status.idle":"2024-11-11T09:57:37.164185Z","shell.execute_reply.started":"2024-11-11T09:57:37.036046Z","shell.execute_reply":"2024-11-11T09:57:37.163397Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"train_df.columns = [\"user_id:token\", \"item_id:token\", \"timestamp:float\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:57:37.165400Z","iopub.execute_input":"2024-11-11T09:57:37.165805Z","iopub.status.idle":"2024-11-11T09:57:37.170855Z","shell.execute_reply.started":"2024-11-11T09:57:37.165758Z","shell.execute_reply":"2024-11-11T09:57:37.169948Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"train_df.to_csv(\"dataset/hm/hm.inter\", sep=\"\\t\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:57:37.172144Z","iopub.execute_input":"2024-11-11T09:57:37.172526Z","iopub.status.idle":"2024-11-11T09:57:39.124444Z","shell.execute_reply.started":"2024-11-11T09:57:37.172483Z","shell.execute_reply":"2024-11-11T09:57:39.123427Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# Model training","metadata":{}},{"cell_type":"code","source":"import sys\nimport os\nimport logging\nimport argparse\nfrom logging import getLogger\nfrom recbole.utils import init_logger, init_seed\nfrom recbole.trainer import Trainer\nfrom mamba4rec import Mamba4Rec\n# from mamba4rec_attr import Mamba4Rec\nfrom recbole.config import Config\nfrom recbole.data import create_dataset, data_preparation\nfrom recbole.data.transform import construct_transform\nfrom recbole.utils import (\n    init_logger,\n    get_model,\n    get_trainer,\n    init_seed,\n    set_color,\n    get_flops,\n    get_environment,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:57:39.125948Z","iopub.execute_input":"2024-11-11T09:57:39.126266Z","iopub.status.idle":"2024-11-11T09:57:54.488799Z","shell.execute_reply.started":"2024-11-11T09:57:39.126232Z","shell.execute_reply":"2024-11-11T09:57:54.487995Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"config = Config(model=Mamba4Rec, config_file_list=[\"config_hm.yaml\"])\ninit_seed(config['seed'], config['reproducibility'])\n\n# logger initialization\ninit_logger(config)\nlogger = getLogger()\nlogger.info(sys.argv)\nlogger.info(config)\n\n# dataset filtering\ndataset = create_dataset(config)\nlogger.info(dataset)\n\n# dataset splitting\ntrain_data, valid_data, test_data = data_preparation(config, dataset)\n\n# model loading and initialization\ninit_seed(config[\"seed\"] + config[\"local_rank\"], config[\"reproducibility\"])\nmodel = Mamba4Rec(config, train_data.dataset).to(config['device'])\nlogger.info(model)\n\ntransform = construct_transform(config)\nflops = get_flops(model, dataset, config[\"device\"], logger, transform)\nlogger.info(set_color(\"FLOPs\", \"blue\") + f\": {flops}\")\n\n# trainer loading and initialization\ntrainer = Trainer(config, model)\n\n\nif os.path.exists(\"saved/checkpoint.pth\"):\n    trainer.resume_checkpoint(\"saved/checkpoint.pth\")\n# model training\nbest_valid_score, best_valid_result = trainer.fit(\n    train_data, valid_data, show_progress=False,\n    saved=True, verbose=True\n)\n\n# trainer.eval_collector.data_collect(train_data)\n# model evaluation\ntest_result = trainer.evaluate(\n    test_data, show_progress=False\n)\n\nenvironment_tb = get_environment(config)\nprint(\n    \"The running environment of this training is as follows:\\n\"\n    + environment_tb.draw()\n)\n\nprint(set_color(\"best valid \", \"yellow\") + f\": {best_valid_result}\")\nprint(set_color(\"test result\", \"yellow\") + f\": {test_result}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:57:54.490146Z","iopub.execute_input":"2024-11-11T09:57:54.490857Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model analysis","metadata":{}},{"cell_type":"markdown","source":"## Item similarity","metadata":{}},{"cell_type":"code","source":"item = pd.read_csv(\"/kaggle/input/h-and-m-personalized-fashion-recommendations/articles.csv\", dtype=dtype)\nitem = item[item[\"article_id\"].isin(data[\"article_id\"])].reset_index()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"item.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Number of total items: {item['article_id'].nunique()}\")\nprint(f\"Number of valid items: {dataset.item_num-1}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"item_str = item.select_dtypes(\"object\")\nitem_str[\"description\"] = item_str.drop(columns=[\"article_id\", \"index_code\"]).apply(lambda x: ' '.join(x.dropna()), axis=1)\nitem = item_str[[\"article_id\", \"description\"]]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"item = item.sort_values(\"article_id\")\nitem_mapper = {item[\"article_id\"].iloc[i]: i for i in range(item[\"article_id\"].nunique())}\nitem_inv_mapper = {i: item[\"article_id\"].iloc[i] for i in range(item[\"article_id\"].nunique())}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom scipy.sparse import csr_matrix\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nvect = TfidfVectorizer()\ntfidf = vect.fit_transform(item[\"description\"])\n\nX = csr_matrix(tfidf)\n\nsvd = TruncatedSVD(n_components=16, n_iter=3, random_state=42)\nX = svd.fit_transform(X)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"valid_articles = dataset.id2token(dataset.iid_field, range(1, dataset.item_num))\nvalid_ids = [item_mapper[item] for item in valid_articles]\nX_valid = X[valid_ids]\nvalid_mapper = {valid_articles[i]: i for i in range(len(valid_articles))}\nvalid_inv_mapper = {i: valid_articles[i] for i in range(len(valid_articles))}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sim_cosine_all = cosine_similarity(X, X)\nsim_cosine_valid = cosine_similarity(X, X_valid)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Map non-data items to valid items","metadata":{}},{"cell_type":"code","source":"from functools import lru_cache\nfrom sklearn.metrics.pairwise import cosine_similarity\n\ndef to_valid_list(item_list):\n\n    global convert2valid\n    @lru_cache(maxsize=2048)  \n    def convert2valid(item):\n        item_id = item_mapper[item]\n        sim_scores = sim_cosine_valid[item_id] # cosine_similarity(X[item_id].reshape(1,-1), X_valid)[0]\n        sort_indices = np.argsort(-sim_scores)\n        return valid_inv_mapper[sort_indices[0]]\n\n    valid_list = []\n    for i in range(len(item_list)-1):\n        if item_list[i] not in valid_articles:\n            valid_list.append(convert2valid(item_list[i]))\n        else:\n            valid_list.append(item_list[i])\n            \n    return ['[PAD]'] if len(valid_list) == 0 else valid_list","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_sequence = test_df.sort_values(['customer_id', 'timestamp']) \\\n                        .groupby('customer_id')['article_id'] \\\n                        .agg(list) \\\n                        .reset_index()\ntest_sequence.columns = [\"customer_id\", \"sequence\"]\nprint(len(test_sequence))\ntest_sequence.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_sequence[\"item_id_list\"] = test_sequence[\"sequence\"].apply(to_valid_list)\ntest_sequence[\"item_length\"] = test_sequence[\"item_id_list\"].apply(len)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_sequence.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Pre- and Post-processing step for non-data item","metadata":{}},{"cell_type":"code","source":"sim_based = True\nK = 10","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import average_precision_score, ndcg_score","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### NDCG on TRAINING test_data","metadata":{}},{"cell_type":"code","source":"total_len = 0\nNDCG_sum = 0\nNDCG_sim_sum = 0 \nfor i, epoch in enumerate(test_data):\n    interaction = epoch[0]    \n    scores = model.full_sort_predict(interaction.to(\"cuda\"))\n    y_scores = scores[:, 1:].cpu().detach().numpy()\n    true_items = dataset.id2token(dataset.iid_field, epoch[3])\n    \n    \n    y_true_cos_sim = sim_cosine_valid[[item_mapper[i] for i in true_items]]\n    y_true_cos = np.eye(dataset.item_num-1)[(epoch[3] - 1)]\n\n    NDCG_sim_sum += ndcg_score(y_true_cos_sim, y_scores) * len(epoch[2])\n    NDCG_sum += ndcg_score(y_true_cos, y_scores) * len(epoch[2])\n    total_len += len(epoch[2])\n\nprint(f\"Hit NDCG on test data: {NDCG_sum / total_len:.3f}\")\nprint(f\"Similarity NDCG on test data: {NDCG_sim_sum / total_len:.3f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### NDCG on NON-TRAINING data","metadata":{}},{"cell_type":"code","source":"# topk_list = []\nshape = (len(test_sequence), dataset.item_num-1)\n\nNDCG_pre = np.zeros(shape[0])\nNDCG_sim_pre = np.zeros(shape[0])\n\nfor i, row in test_sequence.iterrows():\n    item_id_list = np.array([dataset.token2id(dataset.iid_field, row[\"item_id_list\"])])\n    interaction = {\n        \"item_id_list\": torch.LongTensor(item_id_list).to(\"cuda\"),\n        \"item_length\": torch.LongTensor(np.array([row[\"item_length\"]])).to(\"cuda\")\n    }\n    scores = model.full_sort_predict(interaction)[0]\n    y_scores = scores[1:].cpu().detach().numpy().reshape(1,-1)\n\n   \n\n    true_item = row[\"sequence\"][-1]\n    true_item_id = item_mapper[true_item]\n    y_true_cos_sim = sim_cosine_valid[true_item_id, : ].reshape(1,-1)\n\n    true_item = convert2valid(true_item) if true_item not in valid_articles else true_item\n    true_item_id = dataset.token2id(dataset.iid_field, true_item) - 1\n    y_true_cos = np.zeros(shape=(1, shape[1]))\n    y_true_cos[:, true_item_id] = 1\n        \n    NDCG_pre[i] = ndcg_score(y_true_cos, y_scores)\n    NDCG_sim_pre[i] = ndcg_score(y_true_cos_sim, y_scores)\n#print(len(topk_list))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Hit NDCG with preprocessing step: {NDCG_pre.mean():.3f}\")\nprint(f\"Similarity NDCG with preprocessing step: {NDCG_sim_pre.mean():.3f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"non_valid_ids = [item_mapper[item] for item in item_mapper.keys() if item not in valid_articles]\nvalid_ids = [item_mapper[item] for item in valid_articles]\nsim_weights = X_valid / np.sum(X_valid, axis=1).reshape(-1,1)\n\ndef weighted_similarity(initial_scores):\n    final_scores = np.zeros((X.shape[0]))\n    final_scores[valid_ids] = initial_scores\n    \n    # sim_scores = sim_cosine_valid[non_valid_ids][:,match_item_ids]\n    # weights = sim_scores / np.sum(sim_scores, axis=1).reshape(-1,1)\n    \n    final_scores[non_valid_ids] = np.dot(sim_weights, initial_scores)\n    return final_scores.reshape(1,-1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# topk_list = []\n\nNDCG_sim_post = np.zeros(shape[0])\nNDCG_post = np.zeros(shape[0])\nN = shape[1]\nk = 10\nweights = np.array([1/(np.log2(a+2)) for a in range(k)])\n\nfor i, row in test_sequence.iterrows():\n    item_id_list = np.array([dataset.token2id(dataset.iid_field, row[\"item_id_list\"])])\n    interaction = {\n        \"item_id_list\": torch.LongTensor(item_id_list).to(\"cuda\"),\n        \"item_length\": torch.LongTensor(np.array([row[\"item_length\"]])).to(\"cuda\")\n    }\n    scores = model.full_sort_predict(interaction)[0]\n    # scores[0] = -float(\"inf\")\n    scores = scores.cpu().detach().numpy()\n    # top_indices = np.argsort(-scores)[:k]\n    # top_valid_items = dataset.id2token(dataset.iid_field, top_indices)\n    y_scores = weighted_similarity(scores[1:])\n\n    true_item_id = item_mapper[row[\"sequence\"][-1]]\n    y_true_cos_sim = sim_cosine_all[true_item_id, :].reshape(1,-1)\n\n    y_true_cos = np.zeros(shape=(1, X.shape[0]))\n    y_true_cos[:, true_item_id] = 1\n        \n    NDCG_post[i] = ndcg_score(y_true_cos, y_scores)\n    NDCG_sim_post[i] = ndcg_score(y_true_cos_sim, y_scores)\n#print(len(topk_list))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Hit NDCG with pre- and post-processing step: {NDCG_post.mean():.3f}\")\nprint(f\"Similarity NDCG with pre- and post-processing step: {NDCG_sim_post.mean():.3f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}